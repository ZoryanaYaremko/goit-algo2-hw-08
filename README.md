# goit-algo2-hw-08
# Домашнє завдання до модуля “Алгоритми оптимізації та керування ресурсами” (теми 7 та 8)
## Завдання 1. Оптимізація доступу до даних за допомогою LRU-кешу
Реалізований LRU-кеш суттєво зменшує час виконання запитів при повторному доступі до «гарячих» діапазонів даних.
У моделі з 50 000 запитів до масиву з 100 000 елементів:
Без кешу: час виконання	≈ 44 с,	прискорення -
З LRU-кешем: час виконання	≈ 16 с, прискорення	×2.7
Таким чином, кешування дозволяє скоротити час обробки приблизно у 2–3 рази, особливо у випадках, коли більшість запитів повторюють популярні («гарячі») діапазони.
Інвалідація кешу під час оновлення реалізована лінійним проходом по ключах, як вимагалось у технічному завданні.
### Висновок: 
застосування LRU-кешу значно підвищує продуктивність при повторюваних запитах і є ефективним способом оптимізації систем, що часто звертаються до тих самих даних.
<img width="520" height="255" alt="image" src="https://github.com/user-attachments/assets/57effe65-9d10-4297-8b82-a294f639fda4" />

## Завдання 2. Реалізація Rate Limiter з використанням алгоритму Sliding Window для обмеження частоти повідомлень у чаті
Клас SlidingWindowRateLimiter забезпечує точний контроль частоти повідомлень у чат-системі.
Використання ковзного вікна (collections.deque) дає можливість гнучко керувати тимчасовими інтервалами та видаляти застарілі події у реальному часі.
Реалізація пройшла всі критерії прийняття:
- Перше повідомлення завжди дозволено.
- Повторне повідомлення в межах вікна (10 с) блокується.
- Після очищення вікна користувач видаляється з історії.
- Метод time_until_next_allowed() коректно повертає час очікування.
### Висновок: 
Sliding Window Rate Limiter ефективно обмежує частоту запитів і може бути використаний у чат-сервісах або API для запобігання спаму чи надмірному навантаженню.
<img width="514" height="495" alt="image" src="https://github.com/user-attachments/assets/cece042f-de71-412a-9626-cae51d6536ed" />




